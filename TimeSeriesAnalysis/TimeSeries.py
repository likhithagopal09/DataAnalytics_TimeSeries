# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M8WlWJ4nfwiF_yiJnGlNBM7O2gMtwGvq
"""

# Imports & display options
import io, zipfile, re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

pd.set_option("display.max_columns", None)
pd.set_option("display.width", 120)
plt.rcParams["figure.figsize"] = (12, 6)

# Upload file (CSV or ZIP) & load DataFrame
from google.colab import files

uploaded = files.upload()
assert len(uploaded) >= 1, "No file uploaded."

fname = next(iter(uploaded))

def load_dataframe_from_any(fname: str) -> pd.DataFrame:
    if fname.lower().endswith(".csv"):
        return pd.read_csv(io.BytesIO(uploaded[fname]), low_memory=False, on_bad_lines="skip", encoding="utf-8")
    if fname.lower().endswith(".zip"):
        zf = zipfile.ZipFile(io.BytesIO(uploaded[fname]))
        csv_members = [n for n in zf.namelist() if n.lower().endswith(".csv")]
        assert len(csv_members) > 0, "ZIP does not contain a CSV."
        with zf.open(csv_members[0]) as f:
            return pd.read_csv(f, low_memory=False, on_bad_lines="skip", encoding="utf-8")
    return pd.read_csv(fname, low_memory=False, on_bad_lines="skip", encoding="utf-8")

df_raw = load_dataframe_from_any(fname).copy()
df = df_raw.copy()

print("Loaded shape:", df.shape)
df.head(3)

# Clean column names & auto-detect key columns
def normalize(name: str) -> str:
    return re.sub(r"[^a-z0-9]+", "", name.strip().lower())

norm2orig = {}
for c in df.columns:
    norm2orig[normalize(c)] = c

# Convenience search
def find_first(possible_keys):
    for key in possible_keys:
        key_norm = normalize(key)
        for n, orig in norm2orig.items():
            if n == key_norm:
                return orig
        # contains match (e.g., "measurementdate" contains "date")
        for n, orig in norm2orig.items():
            if key_norm in n:
                return orig
    return None

CITY_COL    = find_first(["city", "town", "location", "urbanarea"])
COUNTRY_COL = find_first(["country", "nation"])
DATE_COL    = find_first(["date", "datetime", "day"])
YEAR_COL    = find_first(["year"])
MONTH_COL   = find_first(["month"])

AQI_COL     = find_first(["aqi", "airqualityindex", "air_quality_index"])

cand_cols = ["pm2.5", "pm25", "pm_2_5", "pm10", "no2", "so2", "co", "o3", "ozone",
             "no", "nox", "nh3", "benzene", "toluene", "xylene",
             "temperature", "temp", "humidity", "windspeed", "wind_speed", "dewpoint", "dew_point"]
POLLUTANT_COLS = []
for k in cand_cols:
    c = find_first([k])
    if c and c not in POLLUTANT_COLS:
        POLLUTANT_COLS.append(c)

print("Detected columns:")
print("  City:", CITY_COL)
print("  Country:", COUNTRY_COL)
print("  Date:", DATE_COL, "| Year:", YEAR_COL, "| Month:", MONTH_COL)
print("  AQI:", AQI_COL)
print("  Pollutants/Meteo:", POLLUTANT_COLS)

# Basic inspection
print("Shape:", df.shape)
print("\nDtypes:\n", df.dtypes)
print("\nMissing values (top 20):\n", df.isna().sum().sort_values(ascending=False).head(20))
display(df.head(10))

# Parse/construct date & basic cleaning
if DATE_COL and DATE_COL in df.columns:
    df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors="coerce", utc=True)
elif YEAR_COL:
    y = pd.to_numeric(df[YEAR_COL], errors="coerce")
    if MONTH_COL:
        m = pd.to_numeric(df[MONTH_COL], errors="coerce").fillna(1).astype(int).clip(1, 12)
    else:
        m = 1
    df["__tmp_date__"] = pd.to_datetime({"year": y.astype("Int64"), "month": m, "day": 1}, errors="coerce", utc=True)
    DATE_COL = "__tmp_date__"

# Drop rows with invalid dates
if DATE_COL:
    df = df.dropna(subset=[DATE_COL])

# Convert AQI & pollutants to numeric
if AQI_COL:
    df[AQI_COL] = pd.to_numeric(df[AQI_COL], errors="coerce")

for c in POLLUTANT_COLS:
    df[c] = pd.to_numeric(df[c], errors="coerce")

# Remove obviously invalid AQI values (e.g., negative)
if AQI_COL:
    df = df[(df[AQI_COL].isna()) | (df[AQI_COL] >= 0)]

if DATE_COL:
    df["Year"] = df[DATE_COL].dt.year
    df["Month"] = df[DATE_COL].dt.to_period("M").astype(str)

print("After cleaning shape:", df.shape)
df.head(5)

# High-level summary
if CITY_COL:
    print("Unique cities:", df[CITY_COL].nunique())
    print("Top 10 cities by row count:")
    display(df[CITY_COL].value_counts().head(10))
if COUNTRY_COL:
    print("\nUnique countries:", df[COUNTRY_COL].nunique())
    print("Top 10 countries by row count:")
    display(df[COUNTRY_COL].value_counts().head(10))
if AQI_COL:
    print("\nAQI summary:")
    display(df[AQI_COL].describe())

# AQI trend over time for top cities
if DATE_COL and AQI_COL and CITY_COL:
    top_cities = df[CITY_COL].value_counts().head(5).index.tolist()
    temp = df[df[CITY_COL].isin(top_cities)].sort_values(DATE_COL)
    plt.figure()
    sns.lineplot(data=temp, x=DATE_COL, y=AQI_COL, hue=CITY_COL, errorbar=None)
    plt.title("AQI Trend Over Time (Top Cities by Data Availability)")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
else:
    print("Skipping city AQI trend plot (missing DATE/AQI/CITY columns).")

print("Using group column:", group_col)
print("Unique values in group column:", df[group_col].unique()[:20])
print("AQI sample:", df[AQI_COL].dropna().unique()[:20])

# Force group column to City instead of Country
group_col = CITY_COL

print("Now using group column:", group_col)
print("Unique values in group column:", df[group_col].unique()[:20])

# AQI distribution by City
if AQI_COL and CITY_COL:
    # Pick only top 15 cities with most rows
    top_cities = df[CITY_COL].value_counts().head(15).index
    temp = df[df[CITY_COL].isin(top_cities)].dropna(subset=[AQI_COL])

    if temp.empty:
        print("No valid AQI data for selected cities.")
    else:
        plt.figure(figsize=(14,6))
        sns.boxplot(data=temp, x=CITY_COL, y=AQI_COL, showfliers=False, palette="Set2")
        sns.stripplot(data=temp, x=CITY_COL, y=AQI_COL, color="black", alpha=0.3, jitter=0.2)
        plt.title("AQI Distribution by City (Top 15)")
        plt.xticks(rotation=45, ha="right")
        plt.tight_layout()
        plt.show()
else:
    print("Skipping plot (no AQI or City column).")

# Correlation heatmap for AQI + pollutant/meteorology features
num_cols = []
if AQI_COL: num_cols.append(AQI_COL)
for c in POLLUTANT_COLS:
    if c not in num_cols:
        num_cols.append(c)
num_df = df[num_cols].select_dtypes(include=[np.number])

if num_df.shape[1] >= 2:
    corr = num_df.corr(numeric_only=True)
    plt.figure()
    sns.heatmap(corr, annot=True, fmt=".2f", square=True)
    plt.title("Correlation Heatmap (AQI & Related Features)")
    plt.tight_layout()
    plt.show()
else:
    print("Skipping heatmap (need at least 2 numeric columns among AQI/pollutants).")

# Monthly Average AQI per City (Top 5)
if DATE_COL and AQI_COL and CITY_COL:
    top_cities = df[CITY_COL].value_counts().head(5).index
    temp = df[df[CITY_COL].isin(top_cities)].dropna(subset=[AQI_COL])
    monthly_city = temp.groupby([pd.Grouper(key=DATE_COL, freq="M"), CITY_COL])[AQI_COL].mean().reset_index()

    plt.figure(figsize=(14,6))
    sns.lineplot(data=monthly_city, x=DATE_COL, y=AQI_COL, hue=CITY_COL, marker="o")
    plt.title("Monthly Average AQI (Top 5 Cities)")
    plt.xlabel("Month")
    plt.ylabel("Average AQI")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
else:
    print("Skipping monthly average per city plot.")

# Top 10 most polluted cities by mean AQI
if AQI_COL and CITY_COL:
    city_mean = df.groupby(CITY_COL, dropna=True)[AQI_COL].mean().dropna()
    if not city_mean.empty:
        top10 = city_mean.sort_values(ascending=False).head(10)[::-1]  # reverse for horizontal bar
        plt.figure()
        plt.barh(top10.index, top10.values)
        plt.title("Top 10 Most Polluted Cities (Mean AQI)")
        plt.xlabel("Mean AQI")
        plt.tight_layout()
        plt.show()
    else:
        print("No AQI values to compute city means.")
else:
    print("Skipping Top-10 plot (missing AQI/CITY).")

# Save a cleaned, analysis-ready CSV
save_cols = []
for c in [CITY_COL, COUNTRY_COL, DATE_COL, AQI_COL]:
    if c and c not in save_cols:
        save_cols.append(c)
for c in POLLUTANT_COLS:
    if c not in save_cols:
        save_cols.append(c)
for c in ["Year", "Month"]:
    if c in df.columns and c not in save_cols:
        save_cols.append(c)

clean = df[save_cols].copy() if save_cols else df.copy()
out_name = "aqi_cleaned_ready.csv"
clean.to_csv(out_name, index=False)
print(f"Saved: {out_name}")